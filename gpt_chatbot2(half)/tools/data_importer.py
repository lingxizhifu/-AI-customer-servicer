#!/usr/bin/env python3
"""
å¿«é€Ÿä¿®å¤ç‰ˆæ•°æ®å¯¼å…¥å·¥å…·
è§£å†³æ¨¡å—å¯¼å…¥é—®é¢˜
"""
import sys
import os
import re
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"ğŸ” Pythonè·¯å¾„: {sys.path[:3]}")

# æ£€æŸ¥å¹¶å¯¼å…¥RAGæœåŠ¡
try:
    from services.rag_service import get_rag_service
    print("âœ… RAGæœåŠ¡å¯¼å…¥æˆåŠŸ")
    RAG_AVAILABLE = True
except ImportError as e:
    print(f"âŒ RAGæœåŠ¡å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ’¡ è¯·ç¡®ä¿å·²æŒ‰ç…§æŒ‡å—åˆ›å»ºäº† services/rag_service.py æ–‡ä»¶")
    RAG_AVAILABLE = False

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–"""
    print("\nğŸ” ç¯å¢ƒæ£€æŸ¥:")
    
    # æ£€æŸ¥ç›®å½•ç»“æ„
    required_dirs = ['services', 'tools', 'templates', 'static']
    for dir_name in required_dirs:
        dir_path = os.path.join(project_root, dir_name)
        if os.path.exists(dir_path):
            print(f"âœ… ç›®å½•å­˜åœ¨: {dir_name}/")
        else:
            print(f"âŒ ç›®å½•ç¼ºå¤±: {dir_name}/")
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    key_files = ['app.py', 'services/rag_service.py']
    for file_name in key_files:
        file_path = os.path.join(project_root, file_name)
        if os.path.exists(file_path):
            print(f"âœ… æ–‡ä»¶å­˜åœ¨: {file_name}")
        else:
            print(f"âŒ æ–‡ä»¶ç¼ºå¤±: {file_name}")
    
    # æ£€æŸ¥ä¾èµ–åŒ…
    required_packages = ['chromadb', 'sentence_transformers', 'jieba']
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… åŒ…å·²å®‰è£…: {package}")
        except ImportError:
            print(f"âŒ åŒ…æœªå®‰è£…: {package}")
    
    return RAG_AVAILABLE

def parse_qa_text(text_content: str):
    """è§£æé—®ç­”æ–‡æœ¬æ ¼å¼"""
    qa_pairs = []
    lines = text_content.split('\n')
    current_q = None
    current_a = None
    
    print(f"ğŸ” å¼€å§‹è§£ææ–‡æœ¬ï¼Œå…± {len(lines)} è¡Œ")
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
        if not line or line.startswith('#'):
            continue
        
        # åŒ¹é…é—®é¢˜è¡Œ - æ”¯æŒå¤šç§æ ¼å¼
        if re.match(r'^é—®[ï¼š:]', line) or re.match(r'^Q[ï¼š:]', line, re.IGNORECASE):
            # ä¿å­˜ä¹‹å‰çš„é—®ç­”å¯¹
            if current_q and current_a:
                qa_pairs.append({
                    'question': current_q.strip(),
                    'answer': current_a.strip()
                })
            
            # æå–æ–°é—®é¢˜
            current_q = re.sub(r'^[é—®Q][ï¼š:]', '', line, flags=re.IGNORECASE).strip()
            current_a = None
            
        # åŒ¹é…ç­”æ¡ˆè¡Œ
        elif re.match(r'^ç­”[ï¼š:]', line) or re.match(r'^A[ï¼š:]', line, re.IGNORECASE):
            current_a = re.sub(r'^[ç­”A][ï¼š:]', '', line, flags=re.IGNORECASE).strip()
            
        # ç»­è¡Œå¤„ç†
        elif current_a is not None and line:
            current_a += " " + line
        elif current_q is not None and current_a is None and line:
            current_q += " " + line
    
    # å¤„ç†æœ€åä¸€å¯¹é—®ç­”
    if current_q and current_a:
        qa_pairs.append({
            'question': current_q.strip(),
            'answer': current_a.strip()
        })
    
    print(f"âœ… è§£æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(qa_pairs)} å¯¹é—®ç­”")
    
    # æ˜¾ç¤ºå‰3ä¸ªé—®ç­”ä½œä¸ºé¢„è§ˆ
    if qa_pairs:
        print("\nğŸ“ æ•°æ®é¢„è§ˆ:")
        for i, qa in enumerate(qa_pairs[:3], 1):
            print(f"{i}. Q: {qa['question'][:50]}...")
            print(f"   A: {qa['answer'][:50]}...")
        if len(qa_pairs) > 3:
            print(f"   ... è¿˜æœ‰ {len(qa_pairs) - 3} æ¡æ•°æ®")
    
    return qa_pairs

def parse_json_file(file_path: str):
    """è§£æJSONæ–‡ä»¶"""
    import json
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        qa_data = []
        if isinstance(data, list):
            qa_data = data
        elif isinstance(data, dict):
            if 'qa_pairs' in data:
                qa_data = data['qa_pairs']
            elif 'data' in data:
                qa_data = data['data']
            else:
                qa_data = [data]
        
        # æ ‡å‡†åŒ–å­—æ®µå
        standardized_data = []
        for item in qa_data:
            if isinstance(item, dict):
                question = (item.get('question') or 
                          item.get('q') or 
                          item.get('é—®é¢˜') or "")
                
                answer = (item.get('answer') or 
                        item.get('a') or 
                        item.get('ç­”æ¡ˆ') or "")
                
                if question and answer:
                    standardized_data.append({
                        'question': str(question).strip(),
                        'answer': str(answer).strip(),
                        'category': item.get('category', item.get('ç±»åˆ«', ''))
                    })
        
        print(f"âœ… JSONè§£æå®Œæˆï¼Œæœ‰æ•ˆé—®ç­”å¯¹: {len(standardized_data)}")
        return standardized_data
        
    except Exception as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {e}")
        return []

def parse_csv_file(file_path: str):
    """è§£æCSVæ–‡ä»¶"""
    try:
        import pandas as pd
        
        # å°è¯•ä¸åŒç¼–ç 
        encodings = ['utf-8', 'gbk', 'gb2312']
        df = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                print(f"âœ… ä½¿ç”¨ç¼–ç  {encoding} è¯»å–CSVæ–‡ä»¶æˆåŠŸ")
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            print("âŒ æ— æ³•è¯»å–CSVæ–‡ä»¶")
            return []
        
        qa_data = []
        
        # åˆ—åæ˜ å°„
        question_cols = ['question', 'é—®é¢˜', 'q', 'Question']
        answer_cols = ['answer', 'ç­”æ¡ˆ', 'a', 'Answer']
        
        question_col = None
        answer_col = None
        
        for col in df.columns:
            if col in question_cols:
                question_col = col
            if col in answer_cols:
                answer_col = col
        
        if not question_col or not answer_col:
            print(f"âŒ CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—")
            print(f"å¯ç”¨åˆ—: {list(df.columns)}")
            return []
        
        for _, row in df.iterrows():
            question = str(row[question_col]).strip()
            answer = str(row[answer_col]).strip()
            
            if question != 'nan' and answer != 'nan' and question and answer:
                qa_data.append({
                    'question': question,
                    'answer': answer
                })
        
        print(f"âœ… CSVè§£æå®Œæˆï¼Œæœ‰æ•ˆé—®ç­”å¯¹: {len(qa_data)}")
        return qa_data
        
    except ImportError:
        print("âŒ éœ€è¦å®‰è£…pandas: pip install pandas")
        return []
    except Exception as e:
        print(f"âŒ CSVè§£æå¤±è´¥: {e}")
        return []

def import_to_rag(qa_data):
    """å¯¼å…¥æ•°æ®åˆ°RAGç³»ç»Ÿ"""
    if not RAG_AVAILABLE:
        print("âŒ RAGæœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•å¯¼å…¥æ•°æ®")
        return False
    
    try:
        print(f"ğŸš€ å¼€å§‹å¯¼å…¥ {len(qa_data)} æ¡æ•°æ®åˆ°RAGç³»ç»Ÿ...")
        rag_service = get_rag_service()
        result = rag_service.load_qa_data(qa_data)
        
        print(f"\nğŸ‰ å¯¼å…¥å®Œæˆï¼")
        print(f"âœ… æˆåŠŸå¯¼å…¥: {result['success']} æ¡")
        print(f"âŒ å¯¼å…¥å¤±è´¥: {result['error']} æ¡")
        
        # æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡
        stats = rag_service.get_collection_stats()
        print(f"ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡:")
        print(f"   æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
        print(f"   çŠ¶æ€: {stats['status']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¯¼å…¥RAGç³»ç»Ÿå¤±è´¥: {e}")
        return False

def save_parsed_data(qa_data, output_file):
    """ä¿å­˜è§£æåçš„æ•°æ®"""
    import json
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(qa_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description='å¿«é€Ÿæ•°æ®å¯¼å…¥å·¥å…·')
    parser.add_argument('file_path', help='æ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--type', choices=['text', 'json', 'csv', 'auto'], 
                       default='auto', help='æ–‡ä»¶ç±»å‹')
    parser.add_argument('--check-env', action='store_true', help='åªæ£€æŸ¥ç¯å¢ƒ')
    parser.add_argument('--save-parsed', help='ä¿å­˜è§£æåçš„æ•°æ®åˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--dry-run', action='store_true', help='åªè§£æä¸å¯¼å…¥')
    
    args = parser.parse_args()
    
    # ç¯å¢ƒæ£€æŸ¥
    print("ğŸ”§ å¿«é€Ÿæ•°æ®å¯¼å…¥å·¥å…·")
    env_ok = check_environment()
    
    if args.check_env:
        return
    
    # æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(args.file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.file_path}")
        return
    
    print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {args.file_path}")
    
    # è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹
    file_ext = os.path.splitext(args.file_path)[1].lower()
    if args.type == 'auto':
        if file_ext == '.json':
            args.type = 'json'
        elif file_ext == '.csv':
            args.type = 'csv'
        else:
            args.type = 'text'
        print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹: {args.type}")
    
    # è§£ææ•°æ®
    qa_data = []
    
    if args.type == 'text':
        with open(args.file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        qa_data = parse_qa_text(content)
        
    elif args.type == 'json':
        qa_data = parse_json_file(args.file_path)
        
    elif args.type == 'csv':
        qa_data = parse_csv_file(args.file_path)
    
    if not qa_data:
        print("âŒ æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆæ•°æ®")
        return
    
    # ä¿å­˜è§£æåçš„æ•°æ®
    if args.save_parsed:
        save_parsed_data(qa_data, args.save_parsed)
    
    # å¯¼å…¥åˆ°RAGç³»ç»Ÿ
    if not args.dry_run:
        if env_ok:
            success = import_to_rag(qa_data)
            if success:
                print("\nâœ… æ•°æ®å¯¼å…¥æˆåŠŸï¼æ‚¨ç°åœ¨å¯ä»¥æµ‹è¯•AIå®¢æœçš„å¢å¼ºæ•ˆæœäº†ã€‚")
        else:
            print("\nâš ï¸ ç¯å¢ƒæœªå°±ç»ªï¼Œè·³è¿‡RAGå¯¼å…¥")
            print("ğŸ’¡ è¯·å…ˆæŒ‰ç…§æŒ‡å—åˆ›å»ºå¿…è¦çš„æ–‡ä»¶")
    else:
        print("\nğŸ” è¿™æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œæ•°æ®æœªå®é™…å¯¼å…¥")

if __name__ == "__main__":
    main()